{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b167f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b40f69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>39.551998</td>\n",
       "      <td>41.480000</td>\n",
       "      <td>39.208000</td>\n",
       "      <td>41.015999</td>\n",
       "      <td>90019500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-22</td>\n",
       "      <td>39.820000</td>\n",
       "      <td>40.787998</td>\n",
       "      <td>38.355999</td>\n",
       "      <td>38.546001</td>\n",
       "      <td>93426000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-23</td>\n",
       "      <td>38.868000</td>\n",
       "      <td>39.894001</td>\n",
       "      <td>37.243999</td>\n",
       "      <td>39.098000</td>\n",
       "      <td>132735500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-24</td>\n",
       "      <td>39.966000</td>\n",
       "      <td>39.995998</td>\n",
       "      <td>37.750000</td>\n",
       "      <td>38.125999</td>\n",
       "      <td>70683000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-28</td>\n",
       "      <td>38.240002</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>37.570000</td>\n",
       "      <td>37.740002</td>\n",
       "      <td>51564500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close     Volume  \\\n",
       "0  2019-05-21  39.551998  41.480000  39.208000  41.015999   90019500   \n",
       "1  2019-05-22  39.820000  40.787998  38.355999  38.546001   93426000   \n",
       "2  2019-05-23  38.868000  39.894001  37.243999  39.098000  132735500   \n",
       "3  2019-05-24  39.966000  39.995998  37.750000  38.125999   70683000   \n",
       "4  2019-05-28  38.240002  39.000000  37.570000  37.740002   51564500   \n",
       "\n",
       "   Dividends  Stock Splits  \n",
       "0          0           0.0  \n",
       "1          0           0.0  \n",
       "2          0           0.0  \n",
       "3          0           0.0  \n",
       "4          0           0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('TSLA.CSV').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e099540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\sawan kumar yadav\\anaconda3\\lib\\site-packages (3.5.4)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\sawan kumar yadav\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45f1ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f15c237f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sawan</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tarun</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ajay</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  Age\n",
       "0  Sawan   28\n",
       "1  Tarun   30\n",
       "2   Ajay   27"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In pandas\n",
    "\n",
    "pd.read_excel('test1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b74d46dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d25bb911",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "353acfd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.5:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x28f044a1850>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "757c227a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.csv('TSLA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d9dc09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+---------+---------+------------+\n",
      "|       _c0|               _c1|               _c2|               _c3|               _c4|      _c5|      _c6|         _c7|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+---------+------------+\n",
      "|      Date|              Open|              High|               Low|             Close|   Volume|Dividends|Stock Splits|\n",
      "|2019-05-21|39.551998138427734| 41.47999954223633| 39.20800018310547| 41.01599884033203| 90019500|        0|         0.0|\n",
      "|2019-05-22| 39.81999969482422| 40.78799819946289| 38.35599899291992| 38.54600143432617| 93426000|        0|         0.0|\n",
      "|2019-05-23| 38.86800003051758| 39.89400100708008| 37.24399948120117|39.097999572753906|132735500|        0|         0.0|\n",
      "|2019-05-24|39.965999603271484| 39.99599838256836|             37.75|38.125999450683594| 70683000|        0|         0.0|\n",
      "|2019-05-28|  38.2400016784668|              39.0| 37.56999969482422|  37.7400016784668| 51564500|        0|         0.0|\n",
      "|2019-05-29| 37.41999816894531| 38.47800064086914|37.007999420166016| 37.97200012207031| 59843000|        0|         0.0|\n",
      "|2019-05-30|             37.75| 38.45199966430664| 37.40399932861328| 37.64400100708008| 39632500|        0|         0.0|\n",
      "|2019-05-31| 37.02000045776367| 37.98400115966797| 36.81999969482422| 37.03200149536133| 52033500|        0|         0.0|\n",
      "|2019-06-03| 37.10200119018555| 37.33599853515625| 35.39799880981445| 35.79399871826172| 65322000|        0|         0.0|\n",
      "|2019-06-04|36.220001220703125| 38.79600143432617|35.922000885009766|38.720001220703125| 69037500|        0|         0.0|\n",
      "|2019-06-05|39.736000061035156| 40.25600051879883|38.369998931884766| 39.31800079345703| 67554000|        0|         0.0|\n",
      "|2019-06-06| 40.88800048828125| 42.20000076293945| 40.36000061035156|41.189998626708984|101211000|        0|         0.0|\n",
      "|2019-06-07|              41.0|42.167999267578125| 40.70000076293945|40.900001525878906| 80017500|        0|         0.0|\n",
      "|2019-06-10| 42.04999923706055| 43.38800048828125|41.801998138427734| 42.57600021362305| 52925000|        0|         0.0|\n",
      "|2019-06-11|43.827999114990234| 44.18000030517578| 42.70000076293945| 43.41999816894531| 58267500|        0|         0.0|\n",
      "|2019-06-12| 44.59000015258789| 44.67599868774414| 41.79999923706055| 41.85200119018555| 75987500|        0|         0.0|\n",
      "|2019-06-13| 42.07600021362305| 42.97999954223633| 41.50199890136719| 42.78200149536133| 40841500|        0|         0.0|\n",
      "|2019-06-14|             42.25| 43.33000183105469| 42.08000183105469| 42.98400115966797| 37167000|        0|         0.0|\n",
      "|2019-06-17| 43.09600067138672|45.400001525878906|42.854000091552734| 45.00600051879883| 61584000|        0|         0.0|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+---------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()  # Here it is not giving proper header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9b71594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string, _c5: string, _c6: string, _c7: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7425dd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.option('header','true').csv('TSLA.csv') # to read dataset with proper header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51717a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+---------+---------+------------+\n",
      "|      Date|              Open|              High|               Low|             Close|   Volume|Dividends|Stock Splits|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+---------+------------+\n",
      "|2019-05-21|39.551998138427734| 41.47999954223633| 39.20800018310547| 41.01599884033203| 90019500|        0|         0.0|\n",
      "|2019-05-22| 39.81999969482422| 40.78799819946289| 38.35599899291992| 38.54600143432617| 93426000|        0|         0.0|\n",
      "|2019-05-23| 38.86800003051758| 39.89400100708008| 37.24399948120117|39.097999572753906|132735500|        0|         0.0|\n",
      "|2019-05-24|39.965999603271484| 39.99599838256836|             37.75|38.125999450683594| 70683000|        0|         0.0|\n",
      "|2019-05-28|  38.2400016784668|              39.0| 37.56999969482422|  37.7400016784668| 51564500|        0|         0.0|\n",
      "|2019-05-29| 37.41999816894531| 38.47800064086914|37.007999420166016| 37.97200012207031| 59843000|        0|         0.0|\n",
      "|2019-05-30|             37.75| 38.45199966430664| 37.40399932861328| 37.64400100708008| 39632500|        0|         0.0|\n",
      "|2019-05-31| 37.02000045776367| 37.98400115966797| 36.81999969482422| 37.03200149536133| 52033500|        0|         0.0|\n",
      "|2019-06-03| 37.10200119018555| 37.33599853515625| 35.39799880981445| 35.79399871826172| 65322000|        0|         0.0|\n",
      "|2019-06-04|36.220001220703125| 38.79600143432617|35.922000885009766|38.720001220703125| 69037500|        0|         0.0|\n",
      "|2019-06-05|39.736000061035156| 40.25600051879883|38.369998931884766| 39.31800079345703| 67554000|        0|         0.0|\n",
      "|2019-06-06| 40.88800048828125| 42.20000076293945| 40.36000061035156|41.189998626708984|101211000|        0|         0.0|\n",
      "|2019-06-07|              41.0|42.167999267578125| 40.70000076293945|40.900001525878906| 80017500|        0|         0.0|\n",
      "|2019-06-10| 42.04999923706055| 43.38800048828125|41.801998138427734| 42.57600021362305| 52925000|        0|         0.0|\n",
      "|2019-06-11|43.827999114990234| 44.18000030517578| 42.70000076293945| 43.41999816894531| 58267500|        0|         0.0|\n",
      "|2019-06-12| 44.59000015258789| 44.67599868774414| 41.79999923706055| 41.85200119018555| 75987500|        0|         0.0|\n",
      "|2019-06-13| 42.07600021362305| 42.97999954223633| 41.50199890136719| 42.78200149536133| 40841500|        0|         0.0|\n",
      "|2019-06-14|             42.25| 43.33000183105469| 42.08000183105469| 42.98400115966797| 37167000|        0|         0.0|\n",
      "|2019-06-17| 43.09600067138672|45.400001525878906|42.854000091552734| 45.00600051879883| 61584000|        0|         0.0|\n",
      "|2019-06-18| 45.74399948120117|46.948001861572266|44.512001037597656|44.948001861572266| 63579000|        0|         0.0|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+---------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "266c6c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+---------+---------+------------+\n",
      "|      Date|              Open|              High|               Low|             Close|   Volume|Dividends|Stock Splits|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+---------+------------+\n",
      "|2019-05-21|39.551998138427734| 41.47999954223633| 39.20800018310547| 41.01599884033203| 90019500|        0|         0.0|\n",
      "|2019-05-22| 39.81999969482422| 40.78799819946289| 38.35599899291992| 38.54600143432617| 93426000|        0|         0.0|\n",
      "|2019-05-23| 38.86800003051758| 39.89400100708008| 37.24399948120117|39.097999572753906|132735500|        0|         0.0|\n",
      "|2019-05-24|39.965999603271484| 39.99599838256836|             37.75|38.125999450683594| 70683000|        0|         0.0|\n",
      "|2019-05-28|  38.2400016784668|              39.0| 37.56999969482422|  37.7400016784668| 51564500|        0|         0.0|\n",
      "|2019-05-29| 37.41999816894531| 38.47800064086914|37.007999420166016| 37.97200012207031| 59843000|        0|         0.0|\n",
      "|2019-05-30|             37.75| 38.45199966430664| 37.40399932861328| 37.64400100708008| 39632500|        0|         0.0|\n",
      "|2019-05-31| 37.02000045776367| 37.98400115966797| 36.81999969482422| 37.03200149536133| 52033500|        0|         0.0|\n",
      "|2019-06-03| 37.10200119018555| 37.33599853515625| 35.39799880981445| 35.79399871826172| 65322000|        0|         0.0|\n",
      "|2019-06-04|36.220001220703125| 38.79600143432617|35.922000885009766|38.720001220703125| 69037500|        0|         0.0|\n",
      "|2019-06-05|39.736000061035156| 40.25600051879883|38.369998931884766| 39.31800079345703| 67554000|        0|         0.0|\n",
      "|2019-06-06| 40.88800048828125| 42.20000076293945| 40.36000061035156|41.189998626708984|101211000|        0|         0.0|\n",
      "|2019-06-07|              41.0|42.167999267578125| 40.70000076293945|40.900001525878906| 80017500|        0|         0.0|\n",
      "|2019-06-10| 42.04999923706055| 43.38800048828125|41.801998138427734| 42.57600021362305| 52925000|        0|         0.0|\n",
      "|2019-06-11|43.827999114990234| 44.18000030517578| 42.70000076293945| 43.41999816894531| 58267500|        0|         0.0|\n",
      "|2019-06-12| 44.59000015258789| 44.67599868774414| 41.79999923706055| 41.85200119018555| 75987500|        0|         0.0|\n",
      "|2019-06-13| 42.07600021362305| 42.97999954223633| 41.50199890136719| 42.78200149536133| 40841500|        0|         0.0|\n",
      "|2019-06-14|             42.25| 43.33000183105469| 42.08000183105469| 42.98400115966797| 37167000|        0|         0.0|\n",
      "|2019-06-17| 43.09600067138672|45.400001525878906|42.854000091552734| 45.00600051879883| 61584000|        0|         0.0|\n",
      "|2019-06-18| 45.74399948120117|46.948001861572266|44.512001037597656|44.948001861572266| 63579000|        0|         0.0|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+---------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.option('header','true').csv('TSLA.csv').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b032e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark.read.option('header','true').csv('TSLA.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a32048a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Date='2019-05-21', Open='39.551998138427734', High='41.47999954223633', Low='39.20800018310547', Close='41.01599884033203', Volume='90019500', Dividends='0', Stock Splits='0.0'),\n",
       " Row(Date='2019-05-22', Open='39.81999969482422', High='40.78799819946289', Low='38.35599899291992', Close='38.54600143432617', Volume='93426000', Dividends='0', Stock Splits='0.0'),\n",
       " Row(Date='2019-05-23', Open='38.86800003051758', High='39.89400100708008', Low='37.24399948120117', Close='39.097999572753906', Volume='132735500', Dividends='0', Stock Splits='0.0')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7dafa82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: string (nullable = true)\n",
      " |-- High: string (nullable = true)\n",
      " |-- Low: string (nullable = true)\n",
      " |-- Close: string (nullable = true)\n",
      " |-- Volume: string (nullable = true)\n",
      " |-- Dividends: string (nullable = true)\n",
      " |-- Stock Splits: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()  # It is like df.info of pandas to details of the each fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b7ccef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
